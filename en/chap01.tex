\chapter{Introduction}
Voice communication is a common interface of many systems nowadays.
Voice communication applications range from simple one-word control commands to complex communication in spoken dialogue systems.
In this work, we consider mainly such complex systems.
We now briefly introduce setting of such system.
\par
Leading a reasonable dialogue with a user is a substantially difficult composed of many subtasks.
High level overview of such system is given in \figref{sds}.
First, the input from the user has to be processed
Spoken dialogue systems typically contain Automatic Speech Recognition (ASR) module for this purposes, so the natural speech can be recognized and translated into text.
Afterwards, some Spoken Language Understanding (SLU) technique has to be employed in order to extract essential information from the input.
In plain words, we have to understand the meaning of the utterance obtained from the user.
The dialogue system than derives a relevant response using its policy.
The process of this derivation depends on particular implementation.
A $rule-based$ policy can be used, however it is more common nowadays to employ $data-driven$ approaches.
\par
The derived response then has to be translated into human readable language, using Natural Language Generation (NLG) techniques.
The response can be displayed in textual form, however, it is more common to generate audio recording with human voice reading the response.
Although it is possible to use a set of prerecorded utterances, this approach has obvious limitations since it is not able to read an arbitrary phrase.
Particularly, it may be difficult to read named entities and numerical values such as time and date.
Also, the usage of variable utterances provides better user experience.
\img{SDS.png}{0.9}{A high level architecture of spoken dialogue system. The data flow between respective components is showed. We can see, that different components may work with different data representations.}{sds}
\par
To introduce a variability and allow to use nearly arbitrary phrase a Text-To-Speech (TTS) module is usually also part of dialogue systems.
The purpose of this module is to transform written text utterance to natural speech.
Modern TTS systems produce audio waveforms that sound naturaly and the pronunciation is sufficiently good.
Nevertheless, it may experience some difficulties, mainly when it comes to words that are not containe in the pronunciation lexicon
This may happen, because although some multilingual TTS systems exists (\cite{sproat1997multilingual}, \cite{miro2009multilingual}), the system is usually trained using certain set of words, typically from one language.
But some applications often require to pronounce named entities or other language- or domain-specific words, that cannot be present during the training phase.
Furthermore, the system needs to obtain information, which language it should use.
This does not make much sense when considering individual proper names.
Such words are called Out-Of-Vocabulary (OOV), because the TTS systems are vocabulary based, i.e. they contain set of known words and their phonetic transcriptions.
Occurences of OOV words cause situations, when the system has to employ some mechanism to derive the pronunciation and the words may be mispronounced.
The derivation of the pronunciation is inherently imperfect and may cause errors.
Although this does not occur often, the negative effect can be quite strong, since it is inconvenient for the user, especially when known propername, e.g. his or her name is pronounced with mistakes.
\par
In this work, we aim to improve the TTS system pronunciation of OOV words.
First, we explore methods that can identify words that are potentially difficult to pronounce.
The identification is first step towards the improvement, because it allows us to ask the user for proper pronunciation directly without trying it first.
That saves the user from the unpleasant experience.
We propose and explore several measures that can reflect incorrectly pronounced words without any prior language knowledge.
\par
Next, we try to improve the TTS system's pronuncication of the desired words.
We try to learn it with the help of spoken examples of these words.
To achieve this, we have to gather correct pronunciations first.
Once we get training examples, we are able to improve the TTS system by processing the obtained recording, deriving a phonetic transcription (i.e. pronunciation) and adding it to the TTS vocabulary.
\par
\begin{center}
\begin{figure}[h]
\texttt{System: Hello, /AANDRZHEZH/.\linebreak
User: You said it wrong, my name is /ONDRZHEI/.\linebreak
System: /ANDREY/, correct?\linebreak
User: No, it is /ONDRZHEI/.\linebreak
System: Oh, /ONDRZHEI/?\linebreak
User: That's right.
}
\caption{Sample dialogue illustrating how the pronunciation correction process may look like. The dialogue system pronounces user's name incorrectly. User then correct it and the system learns. The transcriptions of the user's name are given in ARPABET.}
\label{dialogsample}
\end{figure}
\end{center}
There are several issues, that are related with the OOV words so methods of deriving correct pronunciations has got potentially very useful applications.
As it has been said, it can be used to enlarge vocabularies of TTS or ASR systems.
This may potentially lead to better pronunciation in case of TTS.
It is because the extended vocabulary implies, that a number of occurences of the badly pronounced words decreases.
Moreover, the derived pronunciations can be used to improve the recognition ability of the ASR module, since it is also dictionary-based.
Thus if we enlarge the vocabulary, the ASR has got access to more possibilities and can recognize the new words correctly.
Yet another application is related to user experience. It can be, that although the word is contained in the pronunciation lexicon, the respective pronunciation is wrong or the user is just used to pronounce the world in different way.
That is when a method of derivation of pronunciation from the recording may be helpful.
\par
There exist several ways how to obtain the desired recordings, however, this is not a subject of this work.
It is dependent on dialogue policy and can vary in concrete applications.
Theoretically, the method can work with just one gold example, however, it is better to obtain more recordings in general.
In \figref{dialogsample} we provide basic example of simple dialogue, illustrating how real application could look like.
However, in this work we assume the user's recording(s) have been gathered already and we do not discuss the dialogue policy.
